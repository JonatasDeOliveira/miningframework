# This script receives as input the path to a framework input file, the path to a directory generated by the miningframework and a github acess token, it downloads the release files from github and moves the files to the directory passed as input.


import sys
import requests
import json
import subprocess
import time
import shutil
import os
import csv

PATH = "path"
NAME = "name"
RESULT = "result"
GITHUB_API= "https://api.github.com"
TRAVIS_API = "https://api.travis-ci.org"
LOGIN = "login"
DOWNLOAD_URL='browser_download_url'
ASSETS="assets"
MESSAGE_PREFIX="Trigger build #"
RELEASE_PREFIX= "fetchjar-"
jars_build_commits = {}

input_path = sys.argv[1] # input path passed as cli argument
output_path = sys.argv[2] # output path passed as cli argument
token = sys.argv[3] # token passed as cli argument

def fetchJars(input_path, output_path, token):
    # this method reads a csv input file, with the projects name and path
    # for each project it downloads the build generated via github releases
    # and moves the builds to the output generated by the framework
    
    print("Starting build collection")

    token_user = get_github_user(token)[LOGIN]

    parsed_input = read_input(input_path)
    parsed_output = read_output(output_path)
    new_results_file = []

    for project in parsed_input:

        splited_project_path = project[PATH].split('/')
        project_name = splited_project_path[len(splited_project_path) - 1]
        github_project = token_user + '/' + project_name
        print (project_name)        

        get_builds_and_wait(github_project)

        releases = get_github_releases(token, github_project)

        # download the releases for the project moving them to the output directories
        for release in releases:
            # check if release was generated by the framework
            if (release[NAME].startswith(RELEASE_PREFIX)):
                commit_sha = release[NAME].replace(RELEASE_PREFIX, '')
                print ("Downloading " + commit_sha )
                try:
                    download_path = mount_download_path(output_path, project, commit_sha)
                    download_url = release[ASSETS][0][DOWNLOAD_URL]
                    download_file(download_url, download_path)
                    if (commit_sha in parsed_output):
                        new_results_file.append(parsed_output[commit_sha])
                        untar_and_remove_file(download_path)
                    print (download_path + ' is ready')
                except:
                    pass
    
        remove_commit_files_without_builds (output_path, project_name)
      
    with open(output_path + "/data/results-with-builds.csv", 'w') as output_file:
        output_file.write("project;merge commit;className;method;left modifications;left deletions;right modifications;right deletions\n")
        output_file.write("\n".join(new_results_file))
        output_file.close()

def read_output(output_path):
    fo = open(output_path + "/data/results.csv")
    file = fo.read()
    fo.close()

    file_out_lines = file.split("\n")
    return parse_output(file_out_lines)

def parse_output(lines):
    result = {}
    for line in lines[1:]:
        cells = line.split(";")
        if (len (cells) > 1):
            result[cells[1]] = line
    return result

def read_input(input_path):
    f = open(input_path, "r")
    file = f.read()
    f.close()

    brute_lines = file.split("\n")
    return parse_input(brute_lines)

def parse_input(lines):
    # parse framework input csv file 
    result = []
    for line in lines[1:]:
        cells = line.split(",")
        if (len (cells) > 1):
            method = {}
            method[NAME] = cells[0]
            method[PATH] = cells[1]
            result.append(method)
    return result

def download_file(url, target_path, commitSHA):
    # download file from url
    response = requests.get(url, stream=True)
    if response.status_code == 200:
        try:
            save_jar_commit_directory(target_path, response)
            jars_build_commits[commitSHA] = target_path
        except Exception as e: 
            create_directory(target_path)        
            save_jar_commit_directory(target_path, response)
            untar_and_remove_file(target_path)
            jars_build_commits[commitSHA] = target_path

def save_jar_commit_directory(target_path, response):
    with open(target_path, 'wb') as f:
        f.write(response.raw.read())        

def create_directory(target_path):
    target = target_path.split("/result.tar.gz")[0]
    os.mkdir(target)

def mount_download_path(output_path, project, commit_sha):
    # mount path where the downloaded build will be moved to
    return output_path + '/files/' + project[NAME] + '/' + commit_sha + '/result.tar.gz'

def untar_and_remove_file(download_path): 
    download_dir = download_path.replace('result.tar.gz', '')
    subprocess.call(['mkdir', download_dir + 'build'])
    subprocess.call(['tar', '-xf', download_path, '-C', download_dir + '/build', ])
    subprocess.call(['rm', download_path])

def get_builds_and_wait(project):
    has_pendent = True
    filtered_builds = []
    while (has_pendent):
        builds = get_travis_project_builds(project)
        filtered_builds = filter (lambda x: not x["branch"].startswith("untagged"), builds)
        
        has_pendent = False
        for build in filtered_builds:
            print (build["state"])
            has_pendent = has_pendent or (build["state"] != "finished")
    
        if (has_pendent):
            print ("Waiting 30 seconds")
            time.sleep(30)

    return filtered_builds


def get_travis_project_builds(project):
    return requests.get(TRAVIS_API + '/repos/' + project + '/builds').json()

def get_github_user(token):
    return requests.get(GITHUB_API + '/user', headers=get_headers(token)).json()

def get_github_releases(token, project):
    return requests.get(GITHUB_API + '/repos/' + project + '/releases', headers=get_headers(token)).json()

def get_headers(token):
    return {
        "Authorization": "token " + token
    }


def remove_commit_files_without_builds (output_path, project_name):
    files_path = output_path + "/files/" + project_name +  "/"

    if (os.path.exists(files_path)): 
        commit_dirs = os.listdir(files_path)

        for directory in commit_dirs:
            commit_dir = files_path + directory
            build_dir = commit_dir + "/build"

            if (not os.path.exists(build_dir)):
                shutil.rmtree(commit_dir)

        if (len (os.listdir(files_path)) == 0 ):
            shutil.rmtree(files_path)

fetchJars(input_path, output_path, token)