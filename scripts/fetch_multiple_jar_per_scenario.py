import sys
import requests
import json
import subprocess
import time
import shutil
import os
import csv

PATH = "path"
NAME = "name"
RESULT = "result"
GITHUB_API= "https://api.github.com"
TRAVIS_API = "https://api.travis-ci.org"
LOGIN = "login"
DOWNLOAD_URL='browser_download_url'
ASSETS="assets"
MESSAGE_PREFIX="Trigger build #"
RELEASE_PREFIX= "fetchjar-"
jars_build_commits = {}

inputPath = sys.argv[1] # input path passed as cli argument
outputPath = sys.argv[2] # output path passed as cli argument
token = sys.argv[3] # token passed as cli argument

def fetchJars(inputPath, outputPath, token):
    # this method reads a csv input file, with the projects name and path
    # for each project it downloads the build generated via github releases
    # and moves the builds to the output generated by the framework
    
    print("Starting build collection")

    tokenUser = get_github_user(token)[LOGIN]
    parsedInput = read_input(inputPath)
    parsedOutput = read_output(outputPath)
    newResultsFile = []

    for project in parsedInput:

        splitedProjectPath = project[PATH].split('/')
        projectName = splitedProjectPath[len(splitedProjectPath) - 1]
        githubProject = tokenUser + '/' + projectName
        print (projectName)        

        get_builds_and_wait(githubProject)

        releases = get_github_releases(token, githubProject)

        # download the releases for the project moving them to the output directories
        for release in releases:
            # check if release was generated by the framework
            try:
                if (release[NAME].startswith(RELEASE_PREFIX)):
                    commitSHA = release[NAME].replace(RELEASE_PREFIX, '')
                    print ("Downloading " + commitSHA )
                    try:
                        downloadPath = mount_download_path(outputPath, projectName, commitSHA)
                        print("Download Path - " + downloadPath + " \n")
                        downloadUrl = release[ASSETS][0][DOWNLOAD_URL]
                        download_file(downloadUrl, downloadPath, commitSHA)
                        jars_build_commits[commitSHA] = downloadPath
                        if (commitSHA in parsedOutput):
                            newResultsFile.append(parsedOutput[commitSHA])
                            untar_and_remove_file(downloadPath)
                        print (downloadPath + ' is ready')
                    except Exception as e: 
                        print(e)
            except Exception as e: 
                print(e)
        remove_commit_files_without_builds (outputPath, projectName)

    try:
        with open(outputPath + "/data/results-with-builds.csv", 'w') as outputFile:
            outputFile.write("project;merge commit;className;method;left modifications;left deletions;right modifications;right deletions\n")
            outputFile.write("\n".join(newResultsFile))
            outputFile.close()

        output_for_semantic_conflict_study(outputPath, jars_build_commits)
    except Exception as e:
        print(e)

def output_for_semantic_conflict_study(outputPath, jars_build_commits):
    new_output = ""
    with open(outputPath+"/data/results.csv", 'r') as file:
        reader = csv.reader(file)
        count = False
        for row in reader:
            if (count != False):
                values = row[0].split(";")
                path_merge_jar = find_project_jar_for_SHA(jars_build_commits, values, 1)
                path_left_jar = find_project_jar_for_SHA(jars_build_commits, values, 2)
                path_right_jar =  find_project_jar_for_SHA(jars_build_commits, values, 3)
                path_base_jar =  find_project_jar_for_SHA(jars_build_commits, values, 4)
                new_output += format_output(values, path_merge_jar, path_left_jar, path_right_jar, path_base_jar)
            count = True
    create_final_output_file(outputPath, new_output)    

def create_final_output_file(outputPath , contents):
   with open(outputPath + "/data/results_semantic_study.csv", 'w') as outputFile:
        outputFile.write(contents)
        outputFile.close() 

def format_output(values, merge, left, right, base):
    jars_available = "false"
    if (merge != "" and base != "" and (left != "" or right != "")):
        jars_available = "true"

    return values[0]+","+jars_available+","+values[1]+","+values[2]+","+values[3]+","+values[4]+","+values[5]+","+values[6].replace("|",",")+","+values[7]+","+values[8]+","+base+","+left+","+right+","+merge+","+values[9]+","+values[10]+","+values[11]+"\n"

def find_project_jar_for_SHA(jars_build_commits, values, point):
    local_path = os.getcwd()+"/"
    path_jar = ""
    try:
        general_path = jars_build_commits[values[point]]
        for root, dirs, files in os.walk(general_path[:-13]):
            for file in files:
                if file.endswith("jar-with-dependencies.jar"):
                    path_jar += local_path + os.path.join(root, file).replace("\n","")+":"
    except Exception as e:
        print(e)    
    return path_jar

def read_output(outputPath):
    try:
        fo = open(outputPath + "/data/results.csv")
        file = fo.read()
        fo.close()

        fileOutLines = file.split("\n")
        return parse_output(fileOutLines)
    except Exception as e:
        print(e)

def parse_output(lines):
    result = {}
    for line in lines[1:]:
        cells = line.split(";")
        if (len (cells) > 1):
            result[cells[1]] = line
    return result

def read_input(inputPath):
    f = open(inputPath, "r")
    file = f.read()
    f.close()

    bruteLines = file.split("\n")
    return parse_input(bruteLines)

def parse_input(lines):
    # parse framework input csv file 
    result = []
    for line in lines[1:]:
        cells = line.split(",")
        if (len (cells) > 1):
            method = {}
            method[NAME] = cells[0]
            method[PATH] = cells[1]
            result.append(method)
    return result

def download_file(url, target_path, commitSHA):
    # download file from url
    response = requests.get(url, stream=True)
    if response.status_code == 200:
        try:
            save_jar_commit_directory(target_path, response)
            jars_build_commits[commitSHA] = target_path
        except Exception as e: 
            create_directory(target_path)        
            save_jar_commit_directory(target_path, response)
            untar_and_remove_file(target_path)
            jars_build_commits[commitSHA] = target_path

def save_jar_commit_directory(target_path, response):
    with open(target_path, 'wb') as f:
        f.write(response.raw.read())        

def create_directory(target_path):
    target = target_path.split("/result.tar.gz")[0]
    os.mkdir(target)

def mount_download_path(outputPath, project_name, commitSHA):
    # mount path where the downloaded build will be moved to
    return outputPath + '/files/' + project_name + '/' + commitSHA + '/result.tar.gz'

def untar_and_remove_file(downloadPath): 
    downloadDir = downloadPath.replace('result.tar.gz', '')
    subprocess.call(['mkdir', downloadDir + 'build'])
    subprocess.call(['tar', '-xf', downloadPath, '-C', downloadDir + '/build', ])
    subprocess.call(['rm', downloadPath])
    
def get_builds_and_wait(project):
    has_pendent = True
    filtered_builds = []
    try:
        while (has_pendent):
            builds = get_travis_project_builds(project)
            filtered_builds = filter (lambda x: not x["branch"].startswith("untagged"), builds)
            
            has_pendent = False
            for build in filtered_builds:
                print (build["state"])
                has_pendent = has_pendent or (build["state"] != "finished")
        
            if (has_pendent):
                print ("Waiting 30 seconds")
                time.sleep(30)
    except Exception as e:
        print ("Not available build for commit ",e)

    return filtered_builds


def get_travis_project_builds(project):
    return requests.get(TRAVIS_API + '/repos/' + project + '/builds').json()

def get_github_user(token):
    return requests.get(GITHUB_API + '/user', headers=get_headers(token)).json()

def get_github_releases(token, project):
    return requests.get(GITHUB_API + '/repos/' + project + '/releases', headers=get_headers(token)).json()

def get_headers(token):
    return {
        "Authorization": "token " + token
    }


def remove_commit_files_without_builds (outputPath, projectName):
    files_path = outputPath + "/files/" + projectName +  "/"

    if (os.path.exists(files_path)): 
        commit_dirs = os.listdir(files_path)

        for directory in commit_dirs:
            commit_dir = files_path + directory
            build_dir = commit_dir + "/build"

            if (not os.path.exists(build_dir)):
                shutil.rmtree(commit_dir)

        if (len (os.listdir(files_path)) == 0 ):
            shutil.rmtree(files_path)

fetchJars(inputPath, outputPath, token)